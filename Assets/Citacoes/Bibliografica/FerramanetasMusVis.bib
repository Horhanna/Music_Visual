
@phdthesis{hein_designing_2013,
	title = {Designing the {Drum} {Loop}: {A} constructivist {iOS} rhythm tutorial system for beginners},
	url = {http://www.nyu.edu/projects/farbood/thesis/files/Thesis%20examples/Hein_Thesis.pdf},
	language = {en},
	school = {New York University},
	author = {Hein, Ethan},
	year = {2013},
	file = {Hein - Designing the Drum Loop.pdf:C\:\\Users\\rutem\\Zotero\\storage\\EEG4RUE5\\Hein - Designing the Drum Loop.pdf:application/pdf}
}

@misc{lastfm_lastfm_2020,
	title = {Lastfm},
	url = {https://www.last.fm/},
	journal = {Explore as principais músicas com seus Scrobbles},
	author = {LAST.FM},
	year = {2020}
}

@article{wundervald_engenharia_2018,
	title = {Engenharia de {Características} {Baseadas} em {Cifras} para a {Classificação} de {Gêneros} na {Música} {Brasileira}},
	url = {leg.ufpr.br/~walmes/docs/TCC-BrunaWundevald-RogerioHultmannFilho.pdf},
	author = {Wundervald, Bruna Davies},
	year = {2018},
	pages = {52},
	file = {Wundervald - Engenharia de Características Baseadas em Cifras p.pdf:C\:\\Users\\rutem\\Zotero\\storage\\GKDXADPA\\Wundervald - Engenharia de Características Baseadas em Cifras p.pdf:application/pdf}
}

@misc{silva_da_nodate,
	title = {Da {Capo}: {Uma} exploração das representações da música},
	url = {http://www.life.dad.puc-rio.br/projetos/dacapo.html},
	journal = {Laboratório de Interfaces},
	author = {Silva, Mateus Bastos da}
}

@misc{sales_alise_2017,
	title = {Análise da {Música} {Brasileira}},
	url = {https://leosalesblog.wordpress.com/2017/04/21/analise-da-musica-brasileira-parte-2/},
	journal = {Blog},
	author = {Sales, Leonardo},
	month = apr,
	year = {2017}
}

@article{cabral_analyzing_nodate,
	title = {Analyzing {Harmonic} {Progressions} with {HarmIn}: the {Music} of {Antônio} {Carlos} {Jobim}},
	abstract = {This paper describes a tool designed for the analysis, retrieval, and visualization of harmonic progressions which aim to provide the user with valuable statistics and graphs. This output is intended to help the users to better understand the harmonic content of a music dataset, hopefully causing the emergence of interesting findings. The analysis of the music of Antônio Carlos Jobim motivated the creation of our tool, and for this reason is presented as our case study. We also describe how this tool can be integrated into an accompaniment system, going beyond analysis into the fields of interactive music and composition.},
	language = {en},
	author = {Cabral, Giordano and Willey, Robert},
	pages = {12},
	file = {Cabral e Willey - Analyzing Harmonic Progressions with HarmIn the M.pdf:C\:\\Users\\rutem\\Zotero\\storage\\KDZVM9HY\\Cabral e Willey - Analyzing Harmonic Progressions with HarmIn the M.pdf:application/pdf}
}

@article{cantareira_moshviz_2016,
	title = {{MoshViz}: {A} {Detail}+{Overview} {Approach} to {Visualize} {Music} {Elements}},
	volume = {18},
	issn = {1520-9210, 1941-0077},
	shorttitle = {{MoshViz}},
	url = {http://ieeexplore.ieee.org/document/7577795/},
	doi = {10.1109/TMM.2016.2614226},
	abstract = {A music piece contains a large amount of information represented as a series of instructions corresponding to notes that must be played at speciﬁc times. These simple notes are combined to form complex harmonic structures that can be difﬁcult to identify and analyze. Due to its simplicity and straightforward interpretation, music sheets, and piano rolls have been the visual metaphor employed by most music visualization tools to support interpretation. Albeit it can represent all necessary elements to perform a music piece, these metaphors do not explicitly show many of the patterns and structures inherent to music arrangements, such as rhythm progression and harmonic interactions, needing users to create a mental model of them. Moreover, comparing different pieces and visualizing how a particular instrument track relates to the others is an issue not only for music sheet-based techniques but also for most existing music visualization methods. In this paper, we present a novel visualization framework, called Music Overview, Stability and Harmony Visualization (MoshViz), which facilitates the visualization and understanding of music renditions, focusing mainly on the visual analysis of speciﬁc musical instruments. Our approach creates a high-level model of music data and highlights structures of interest, enabling a detail+overview visualization to assist users in the task of identifying harmonic and melodic patterns. The usefulness and representativeness of MoshViz is conﬁrmed by a set of user tests which demonstrate that the proposed visual metaphor matches, with a high degree of accuracy, the mental model of different users regarding the recognizable patterns of sounds.},
	language = {en},
	number = {11},
	urldate = {2020-06-03},
	journal = {IEEE Trans. Multimedia},
	author = {Cantareira, Gabriel Dias and Nonato, Luis Gustavo and Paulovich, Fernando V.},
	month = nov,
	year = {2016},
	pages = {2238--2246},
	file = {Cantareira et al. - 2016 - MoshViz A Detail+Overview Approach to Visualize M.pdf:C\:\\Users\\rutem\\Zotero\\storage\\7C88UI7H\\Cantareira et al. - 2016 - MoshViz A Detail+Overview Approach to Visualize M.pdf:application/pdf}
}

@article{bittner_medleydb_2014,
	title = {{MedleyDB}: {A} {MULTITRACK} {DATASET} {FOR} {ANNOTATION}-{INTENSIVE} {MIR} {RESEARCH}},
	abstract = {We introduce MedleyDB: a dataset of annotated, royaltyfree multitrack recordings. The dataset was primarily developed to support research on melody extraction, addressing important shortcomings of existing collections. For each song we provide melody f0 annotations as well as instrument activations for evaluating automatic instrument recognition. The dataset is also useful for research on tasks that require access to the individual tracks of a song such as source separation and automatic mixing. In this paper we provide a detailed description of MedleyDB, including curation, annotation, and musical content. To gain insight into the new challenges presented by the dataset, we run a set of experiments using a state-of-the-art melody extraction algorithm and discuss the results. The dataset is shown to be considerably more challenging than the current test sets used in the MIREX evaluation campaign, thus opening new research avenues in melody extraction research.},
	language = {en},
	author = {Bittner, Rachel and Salamon, Justin and Tierney, Mike and Mauch, Matthias and Cannam, Chris and Bello, Juan},
	year = {2014},
	pages = {6},
	file = {Bittner et al. - 2014 - MedleyDB A MULTITRACK DATASET FOR ANNOTATION-INTE.pdf:C\:\\Users\\rutem\\Zotero\\storage\\EAVC2MLQ\\Bittner et al. - 2014 - MedleyDB A MULTITRACK DATASET FOR ANNOTATION-INTE.pdf:application/pdf}
}

@article{cuthbert_music21_2010,
	title = {music21: {A} {Toolkit} for {Computer}-{Aided} {Musicology} and {Symbolic} {Music} {Data}},
	abstract = {Music21 is an object-oriented toolkit for analyzing, searching, and transforming music in symbolic (scorebased) forms. The modular approach of the project allows musicians and researchers to write simple scripts rapidly and reuse them in other projects. The toolkit aims to provide powerful software tools integrated with sophisticated musical knowledge to both musicians with little programming experience (especially musicologists) and to programmers with only modest music theory skills.},
	language = {en},
	author = {Cuthbert, Michael Scott and Ariza, Christopher},
	year = {2010},
	pages = {7},
	file = {Cuthbert e Ariza - 2010 - music21 A Toolkit for Computer-Aided Musicology a.pdf:C\:\\Users\\rutem\\Zotero\\storage\\84NPKSRH\\Cuthbert e Ariza - 2010 - music21 A Toolkit for Computer-Aided Musicology a.pdf:application/pdf}
}
